IMLIP 2022 多语种图像描述生成评测任务

为促进多语种智能信息处理研究，加强产学研交流与合作，中国人工智能学会多语种智能信息处理专委会发布“多语种图像描述生成评测任务”。
1.	任务背景
图像描述生成任务（Image Captioning）旨在生成描述图像的自然语言，该任务涉及到自然语言处理和计算机视觉两个领域多方面的研究问题。近年来受到学术界和工业界的广泛关注，也出现了一些有价值的应用。随着深度学习技术的发展，端到端图像描述生成系统的表现有了大幅度提升。目前图像描述生成任务的公开数据集多为英语和汉语，为了推动多语种图像描述生成研究的发展，我们汇集整理了蒙语、藏语和维语三个语种的图像描述生成数据集，开展本次多语种图像描述生成评测任务，聚焦该任务涉及到的前沿问题，进一步推动多语种智能信息处理研究的发展。
2.	任务简介
组织者 
- 赵小兵（中央民族大学）
- 李  琳（青海师范大学）
- 孙  媛（中央民族大学）
- 何中军（百度）
- 周园春（中国科学院计算机网络信息中心）
联系人
- 高歌（中央民族大学）
- 崔璐明（青海师范大学）
评测任务更详细内容可查看评测网站：
https://github.com/Ming-360/IMLIP-2022-Image-Caption-evaluation-task
遇到任何问题请发邮件imlip_2022@163.com或者在Issue中提问，欢迎大家参与。
3.	任务简介
图像描述生成任务的目的是为给定图像自动生成高质量的描述文本。本评测任务分为三个子任务，分别为蒙古语、藏语和维吾尔语的图像描述任务。
子任务1	蒙语图像描述生成
子任务2	藏语图像描述生成
子任务2	维语图像描述生成
参赛者可以根据自己的研究兴趣，参与一个或多个子任务。本评测任务要求各位参赛者在现有评测系统基础上针对给定的测试集，研发新的自动评测算法，该评测算法要求在测试集上所得评测结果尽可能地与人工评测结果一致。我们将为参与者提供任务所需数据集和评价方法，并采用客观的评价指标结果作为提交算法的最终成绩。
4.	评测数据简介下载
本节介绍各子任务数据集的来源及数据集使用规则、数据集下载链接及评测结果文件的提交格式。本次评测任务所用数据集来自图像描述生成任务的公开数据集Flickr8k，采用机器翻译结合人工校对的方式，我们开发了蒙语、藏语和维吾尔语的Flickr8k数据集。数据集发布后请各位参赛者自行下载并查阅。
4.1	蒙语图像描述生成子任务
（1）蒙语图像描述生成数据集样本实例

参考1	ᠨᠣᠬᠠᠢ ᠶᠠᠭ ᠤᠯᠠᠭᠠᠨ ᠪᠦᠮᠪᠦᠭᠡ ᠨᠠᠭᠠᠳᠴᠤ ᠪᠠᠢᠢᠨ᠎ᠠ᠃
狗狗正在玩红色的小球
	参考2	ᠨᠣᠬᠠᠢ ᠨᠠᠭᠠᠳᠴᠤ ᠪᠠᠢ᠌ᠨ᠎ᠠ ᠃
一个小狗在玩耍
	参考3	ᠨᠢᠭᠡ ᠨᠣᠬᠠᠢ ᠨᠠᠭᠠᠳᠴᠤ ᠪᠠᠶᠢᠨ᠎ᠠ᠃
一只狗在玩球
	参考4	ᠨᠢᠭᠡ ᠨᠣᠬᠠᠢ ᠪᠥᠮᠪᠥᠭᠡ ᠨᠠᠭᠠᠳᠴᠤ ᠪᠠᠢ᠌ᠨ᠎ᠠ ᠃
小狗在玩耍
	参考5	ᠨᠢᠭᠡ ᠨᠣᠬᠠᠢ ᠨᠠᠭᠠᠳᠴᠤ ᠪᠠᠶᠢᠨ᠎ᠠ᠃
一只狗狗在玩耍
（2）蒙语图像描述数据集下载
	下载地址	公布日期
训练集	【训练集】
11月15日
开发集	【开发集】
11月15日
测试集	【测试集】	3月10日

4.2	藏语图像描述生成子任务
（1）藏语图像描述生成数据集样本实例

参考1	ཁྱི་ཕྲུག་གིས་རྩེད་མོ་རྩེ་བཞིན་འདུག
小狗在玩耍。
	参考2	ཁྱི་ཞིག་གིས་སྤོ་ལོ་རྩེད་བཞིན་འདུག
一只狗在耍球。
	参考3	ཁྱི་ཕྲུག་གཅིག་གིས་རྩེད་མོ་རྩེ་བཞིན་འདུག
一个小狗在玩耍。
	参考4	ཁྱི་ཡིས་སྤོ་ལོ་དམར་པོ་རྩེད་བཞིན་ཡོད།
狗狗正在玩红色的小球。
	参考5	ཁྱི་ཞིག་གིས་རྩེད་མོ་རྩེ་བཞིན་འདུག
一只狗狗在玩耍。
（2）藏语图像描述数据集下载
	下载地址	公布日期
训练集	【训练集】
11月15日
开发集	【开发集】
11月15日
测试集	【测试集】	3月10日
 
4.3	维语图像描述生成子任务
（1）维语图像描述生成数据集样本实例

参考1	ئىت قىزىل شار ئوينىماقتا.
狗狗正在玩红色的小球
	参考2	بىر ئىت ئوينىماقتا.
一个小狗在玩耍
	参考3	بىر ئىت توپ ئوينىماقتا.
一只狗在玩球
	参考4	ئىت ئوينىماقتا.
小狗在玩耍
	参考5	بىر ئىت ئوينىماقتا.
一只狗狗在玩耍
（2）维语图像描述数据集下载
	下载地址	公布日期
训练集	【训练集】
11月15日
开发集	【开发集】
11月15日
测试集	【测试集】	3月10日

5.	结果提交
5.1	结果提交格式
参赛者需提供与给定数据集原始句子索引号相对应的评测结果。方便赛事官方进行结果校验。
提交前，文件需依规范正确命名，并压缩成 .zip 格式文件的压缩包。提交结果命名：track1_test.zip	#压缩包名字
    └── yaclc-csc-test.cvs	# 预测结果文件
5.2	提交方式
请参赛者将以下材料以邮箱形式进行提交：
（1）相关技术文档；
（2）在给定测试集上的评测结果
6.	评价标准
目前的图像描述生成常用的评测指标包括BLEU、METEOR、ROUGE和CIDEr等。但自动评测方法也存在许多不足之处，如强调生成文本与标准答案之间的 n-gram 重叠，而不考虑生成文本的准确性来评价系统。为了深入理解并解决图像描述生成系统评测问题，先提出本共享任务。
同时为保证参赛者作品的真实性和有效性，我们将通过计算各参赛团队算法提交的自动评测结果和人工评测结果之间的肯德尔等级相关系数（Kendall's tau coefficient）来衡量该算法的好坏，得分高者为优。
 
7.	评测赛程
时间	事项
11月10日 - 3月10日	报名阶段，邮件方式
11月15日	发布所有赛道的训练集和开发集
3月10日	发布测试集
3月20日	参赛系统结果提交入口开放
4月20日	参赛系统结果提交入口关闭
4月30日	截止提交评测任务技术报告
5月30日	公布评测结果
6月	评测研讨会
8.	报名方式
以机构、团体或个人名义均可报名参加，有意向的参赛者可通过发送邮件的方式进行报名，地址为imlip_2022@163.com，参赛者应提供队名、单位、联系方式等个人信息，方便与各位参赛者取得联系。
 
参考文献
1.	Li X, Lan W, Dong J, et al. Adding chinese captions to images[C]//Proceedings of the 2016 ACM on international conference on multimedia retrieval. 2016: 271-275.
2.	Papineni K, Roukos S, Ward T, et al. Bleu: a method for automatic evaluation of machine translation[C]//Proceedings of the 40th annual meeting of the Association for Computational Linguistics. 2002: 311-318.
3.	Lin C Y. Rouge: A package for automatic evaluation of summaries[C]//Text summarization branches out. 2004: 74-81.
4.	Banerjee S, Lavie A. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments[C]//Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. 2005: 65-72.
5.	Vedantam R, Lawrence Zitnick C, Parikh D. Cider: Consensus-based image description evaluation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 4566-4575.
6.	Vinyals O, Toshev A, Bengio S, et al. Show and tell: A neural image caption generator[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 3156-3164.
